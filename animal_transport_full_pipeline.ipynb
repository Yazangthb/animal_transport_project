{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal Animal Transport Mode Planning\n",
    "\n",
    "This notebook implements an end-to-end multimodal AI pipeline:\n",
    "\n",
    "1. **Deterministic rule engine** for animal transport mode planning.\n",
    "2. **Synthetic dataset generation** for instruction tuning.\n",
    "3. **LoRA fine-tuning** of a Qwen-style 3B LLM on JSON-structured outputs.\n",
    "4. **Vision-language front-end** using a Qwen-VL model to infer animal attributes from images.\n",
    "5. **Full pipeline:** image → attributes → distance → JSON transport plan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "\n",
    "Uncomment and run the cell below if you need to install dependencies in a fresh environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running in a fresh environment, uncomment and run these installs once.\n",
    "# You may want to pin versions compatible with your CUDA / PyTorch setup.\n",
    "\n",
    "# !pip install -U \"torch\" \"torchvision\" \"torchaudio\" --index-url https://download.pytorch.org/whl/cu121\n",
    "# !pip install -U transformers accelerate peft datasets pillow tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Global Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniconda3/envs/animal/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "from dataclasses import dataclass, asdict\n",
    "from typing import List, Dict, Any, Tuple\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from datasets import Dataset as HFDataset\n",
    "from transformers import (\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    AutoProcessor,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling,\n",
    ")\n",
    "\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Ensure reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Model names (adapt as needed)\n",
    "VLM_MODEL_NAME = \"Qwen/Qwen2.5-VL-3B-Instruct\"   # or another Qwen-VL variant\n",
    "LLM_BASE_NAME = \"Qwen/Qwen2.5-3B-Instruct\"\n",
    "\n",
    "# Paths\n",
    "OUTPUT_DIR = \"./animal_transport_lora\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Rule Engine and Haversine Distance\n",
    "\n",
    "The rule engine encodes allowed / disallowed transport modes and travel time computation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Transport mode definitions and config ---\n",
    "\n",
    "TRANSPORT_MODES = [\n",
    "    \"car_cabin\",\n",
    "    \"car_crate\",\n",
    "    \"van_cargo\",\n",
    "    \"truck_livestock\",\n",
    "    \"bus_cabin\",\n",
    "    \"train_cabin\",\n",
    "    \"train_cargo\",\n",
    "    \"plane_cabin\",\n",
    "    \"plane_cargo\",\n",
    "    \"specialized_animal_freight\",\n",
    "]\n",
    "\n",
    "# Approximate average speeds (km/h)\n",
    "MODE_SPEED_KMH = {\n",
    "    \"car_cabin\": 80,\n",
    "    \"car_crate\": 80,\n",
    "    \"van_cargo\": 70,\n",
    "    \"truck_livestock\": 60,\n",
    "    \"bus_cabin\": 70,\n",
    "    \"train_cabin\": 100,\n",
    "    \"train_cargo\": 80,\n",
    "    \"plane_cabin\": 800,\n",
    "    \"plane_cargo\": 800,\n",
    "    \"specialized_animal_freight\": 65,\n",
    "}\n",
    "\n",
    "# Fixed handling overhead (hours)\n",
    "MODE_OVERHEAD_H = {\n",
    "    \"car_cabin\": 0.25,\n",
    "    \"car_crate\": 0.5,\n",
    "    \"van_cargo\": 0.5,\n",
    "    \"truck_livestock\": 1.0,\n",
    "    \"bus_cabin\": 0.5,\n",
    "    \"train_cabin\": 0.5,\n",
    "    \"train_cargo\": 1.0,\n",
    "    \"plane_cabin\": 2.5,\n",
    "    \"plane_cargo\": 4.0,\n",
    "    \"specialized_animal_freight\": 2.0,\n",
    "}\n",
    "\n",
    "\n",
    "def haversine_distance_km(lat1, lon1, lat2, lon2) -> float:\n",
    "    \"\"\"Compute Haversine distance between two coordinates (in degrees).\"\"\"\n",
    "    R = 6371.0  # Earth radius in km\n",
    "    phi1 = math.radians(lat1)\n",
    "    phi2 = math.radians(lat2)\n",
    "    dphi = math.radians(lat2 - lat1)\n",
    "    dlambda = math.radians(lon2 - lon1)\n",
    "\n",
    "    a = (\n",
    "        math.sin(dphi / 2) ** 2\n",
    "        + math.cos(phi1) * math.cos(phi2) * math.sin(dlambda / 2) ** 2\n",
    "    )\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "\n",
    "    return R * c\n",
    "\n",
    "\n",
    "def estimate_travel_time_hours(distance_km: float, mode: str) -> float:\n",
    "    v = MODE_SPEED_KMH[mode]\n",
    "    overhead = MODE_OVERHEAD_H[mode]\n",
    "    return distance_km / v + overhead\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rule Constraints\n",
    "\n",
    "We define constraints based on:\n",
    "\n",
    "- `animal_category`: small_pet, medium_pet, large_livestock, bird, reptile, wild_dangerous  \n",
    "- `size_class`: small, medium, large  \n",
    "- `is_domesticated`: bool  \n",
    "- `dangerous_to_humans`: bool  \n",
    "- `distance_km`: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b8917c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 23 23:03:56 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB            Off| 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   34C    P0               50W / 300W|      7MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       832      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANIMAL_CATEGORIES = [\n",
    "    \"small_pet\",\n",
    "    \"medium_pet\",\n",
    "    \"large_livestock\",\n",
    "    \"bird\",\n",
    "    \"reptile\",\n",
    "    \"wild_dangerous\",\n",
    "]\n",
    "\n",
    "SIZE_CLASSES = [\"small\", \"medium\", \"large\"]\n",
    "\n",
    "\n",
    "def constraints_satisfied(\n",
    "    animal_category: str,\n",
    "    size_class: str,\n",
    "    is_domesticated: bool,\n",
    "    dangerous_to_humans: bool,\n",
    "    distance_km: float,\n",
    "    mode: str,\n",
    ") -> bool:\n",
    "    \"\"\"Hand-crafted constraints for allowed transport modes.\"\"\"\n",
    "    # Wild or dangerous animals: NO passenger cabins of public transport\n",
    "    if dangerous_to_humans or animal_category == \"wild_dangerous\":\n",
    "        if mode in {\"bus_cabin\", \"train_cabin\", \"plane_cabin\", \"car_cabin\"}:\n",
    "            return False\n",
    "\n",
    "    # Very long distances -> prefer air or specialized freight\n",
    "    if distance_km > 1500:\n",
    "        if mode in {\"car_cabin\", \"car_crate\", \"van_cargo\", \"truck_livestock\", \"bus_cabin\"}:\n",
    "            return False\n",
    "\n",
    "    # Large livestock: require truck_livestock or plane_cargo / specialized freight\n",
    "    if animal_category == \"large_livestock\":\n",
    "        if mode not in {\"truck_livestock\", \"plane_cargo\", \"specialized_animal_freight\"}:\n",
    "            return False\n",
    "\n",
    "    # Small pets: can be in cabin (car, bus, train, plane) for shorter trips\n",
    "    if animal_category == \"small_pet\" and not dangerous_to_humans:\n",
    "        if distance_km <= 1200:\n",
    "            if mode in {\"car_cabin\", \"bus_cabin\", \"train_cabin\", \"plane_cabin\", \"car_crate\"}:\n",
    "                return True\n",
    "\n",
    "    # Birds: typically crate + cabin for short trips, cargo for long trips\n",
    "    if animal_category == \"bird\":\n",
    "        if distance_km <= 1000:\n",
    "            if mode in {\"car_crate\", \"plane_cabin\", \"train_cargo\"}:\n",
    "                return True\n",
    "        else:\n",
    "            if mode in {\"plane_cargo\", \"specialized_animal_freight\"}:\n",
    "                return True\n",
    "\n",
    "    # Reptiles: crate only, and no passenger cabins for long trips\n",
    "    if animal_category == \"reptile\":\n",
    "        if distance_km <= 500:\n",
    "            if mode in {\"car_crate\", \"van_cargo\"}:\n",
    "                return True\n",
    "        if mode in {\"plane_cargo\", \"specialized_animal_freight\"} and distance_km > 500:\n",
    "            return True\n",
    "        if mode in {\"bus_cabin\", \"train_cabin\", \"plane_cabin\"}:\n",
    "            return False\n",
    "\n",
    "    # Medium pets (dogs/cats etc.)\n",
    "    if animal_category == \"medium_pet\" and not dangerous_to_humans:\n",
    "        if distance_km <= 800:\n",
    "            if mode in {\"car_cabin\", \"car_crate\", \"bus_cabin\", \"train_cabin\"}:\n",
    "                return True\n",
    "        if mode in {\"train_cargo\", \"plane_cargo\"} and distance_km > 800:\n",
    "            return True\n",
    "\n",
    "    # Default safety rules:\n",
    "    # - Specialized freight always allowed for non-extreme cases\n",
    "    if mode == \"specialized_animal_freight\":\n",
    "        return True\n",
    "\n",
    "    # Fallback: disallow if no positive rule triggered\n",
    "    return False\n",
    "\n",
    "\n",
    "def generate_transport_plan(\n",
    "    animal_category: str,\n",
    "    size_class: str,\n",
    "    is_domesticated: bool,\n",
    "    dangerous_to_humans: bool,\n",
    "    distance_km: float,\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"Generate allowed/disallowed modes and reasoning string.\"\"\"\n",
    "    allowed_modes = []\n",
    "    disallowed_modes = []\n",
    "\n",
    "    for m in TRANSPORT_MODES:\n",
    "        if constraints_satisfied(\n",
    "            animal_category, size_class, is_domesticated, dangerous_to_humans, distance_km, m\n",
    "        ):\n",
    "            allowed_modes.append(m)\n",
    "        else:\n",
    "            disallowed_modes.append(m)\n",
    "\n",
    "    # Simple textual reasoning:\n",
    "    reasons = []\n",
    "    if dangerous_to_humans or animal_category == \"wild_dangerous\":\n",
    "        reasons.append(\n",
    "            \"Dangerous or wild animals are not permitted in passenger cabins of public transport.\"\n",
    "        )\n",
    "    if animal_category == \"large_livestock\":\n",
    "        reasons.append(\n",
    "            \"Large livestock require trucks, plane cargo, or specialized animal freight.\"\n",
    "        )\n",
    "    if animal_category in {\"small_pet\", \"medium_pet\"} and not dangerous_to_humans:\n",
    "        reasons.append(\n",
    "            \"Small and medium domesticated pets may travel in cabins for short distances; \"\n",
    "            \"long distances prefer cargo or specialized options.\"\n",
    "        )\n",
    "    if animal_category == \"bird\":\n",
    "        reasons.append(\n",
    "            \"Birds typically travel in crates; short trips may use cabin or train cargo, \"\n",
    "            \"while long trips require air cargo or specialized freight.\"\n",
    "        )\n",
    "    if animal_category == \"reptile\":\n",
    "        reasons.append(\n",
    "            \"Reptiles must travel in secure crates, often in cargo or specialized vehicles.\"\n",
    "        )\n",
    "    if distance_km > 1500:\n",
    "        reasons.append(\n",
    "            \"Long-distance travel favors air transport or specialized freight due to time and welfare.\"\n",
    "        )\n",
    "\n",
    "    reasoning = \" \".join(reasons) if reasons else \"Standard welfare and safety rules applied.\"\n",
    "\n",
    "    # Add simple travel time estimates for allowed modes\n",
    "    travel_times = {\n",
    "        m: round(estimate_travel_time_hours(distance_km, m), 2) for m in allowed_modes\n",
    "    }\n",
    "\n",
    "    plan = {\n",
    "        \"available_modes\": allowed_modes,\n",
    "        \"disallowed_modes\": disallowed_modes,\n",
    "        \"distance_km\": round(distance_km, 1),\n",
    "        \"estimated_travel_time_hours\": travel_times,\n",
    "        \"reasoning\": reasoning,\n",
    "    }\n",
    "    return plan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Synthetic Dataset Generation\n",
    "\n",
    "We generate synthetic problems with random animal attributes and origin/destination pairs.\n",
    "Ground-truth JSON transport plans are obtained from the rule engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5bf642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are an expert assistant for animal transport mode planning.\n",
    "Given an animal profile and a travel distance, you must output a JSON object\n",
    "describing allowed and disallowed transport modes and a short reasoning string.\n",
    "\n",
    "Follow this JSON schema exactly:\n",
    "\n",
    "{\n",
    "  \"available_modes\": [string, ...],\n",
    "  \"disallowed_modes\": [string, ...],\n",
    "  \"distance_km\": number,\n",
    "  \"estimated_travel_time_hours\": {string: number, ...},\n",
    "  \"reasoning\": string\n",
    "}\n",
    "\n",
    "Do not add extra keys. Do not output anything outside the JSON (no markdown, no comments).\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class AnimalExample:\n",
    "    animal_category: str\n",
    "    size_class: str\n",
    "    is_domesticated: bool\n",
    "    dangerous_to_humans: bool\n",
    "    origin_lat: float\n",
    "    origin_lon: float\n",
    "    dest_lat: float\n",
    "    dest_lon: float\n",
    "    distance_km: float\n",
    "    plan: Dict[str, Any]\n",
    "\n",
    "\n",
    "def random_coord():\n",
    "    # Roughly realistic lat/lon\n",
    "    lat = random.uniform(-60, 60)\n",
    "    lon = random.uniform(-170, 170)\n",
    "    return lat, lon\n",
    "\n",
    "\n",
    "def generate_synthetic_example() -> AnimalExample:\n",
    "    animal_category = random.choice(ANIMAL_CATEGORIES)\n",
    "    size_class = random.choice(SIZE_CLASSES)\n",
    "\n",
    "    # Simple heuristics for flags\n",
    "    if animal_category in {\"wild_dangerous\", \"reptile\"}:\n",
    "        is_domesticated = False\n",
    "    else:\n",
    "        is_domesticated = random.random() < 0.9\n",
    "\n",
    "    if animal_category == \"wild_dangerous\":\n",
    "        dangerous_to_humans = True\n",
    "    elif animal_category == \"reptile\":\n",
    "        dangerous_to_humans = random.random() < 0.4\n",
    "    else:\n",
    "        dangerous_to_humans = random.random() < 0.1\n",
    "\n",
    "    lat1, lon1 = random_coord()\n",
    "    lat2, lon2 = random_coord()\n",
    "    distance_km = haversine_distance_km(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    plan = generate_transport_plan(\n",
    "        animal_category,\n",
    "        size_class,\n",
    "        is_domesticated,\n",
    "        dangerous_to_humans,\n",
    "        distance_km,\n",
    "    )\n",
    "\n",
    "    return AnimalExample(\n",
    "        animal_category=animal_category,\n",
    "        size_class=size_class,\n",
    "        is_domesticated=is_domesticated,\n",
    "        dangerous_to_humans=dangerous_to_humans,\n",
    "        origin_lat=lat1,\n",
    "        origin_lon=lon1,\n",
    "        dest_lat=lat2,\n",
    "        dest_lon=lon2,\n",
    "        distance_km=distance_km,\n",
    "        plan=plan,\n",
    "    )\n",
    "\n",
    "\n",
    "def example_to_input_json(ex: AnimalExample) -> Dict[str, Any]:\n",
    "    return {\n",
    "        \"animal_category\": ex.animal_category,\n",
    "        \"size_class\": ex.size_class,\n",
    "        \"is_domesticated\": ex.is_domesticated,\n",
    "        \"dangerous_to_humans\": ex.dangerous_to_humans,\n",
    "        \"origin\": {\"lat\": round(ex.origin_lat, 4), \"lon\": round(ex.origin_lon, 4)},\n",
    "        \"destination\": {\"lat\": round(ex.dest_lat, 4), \"lon\": round(ex.dest_lon, 4)},\n",
    "        \"distance_km\": round(ex.distance_km, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "def generate_dataset(num_samples: int) -> List[Dict[str, Any]]:\n",
    "    data = []\n",
    "    for _ in tqdm(range(num_samples), desc=\"Generating synthetic examples\"):\n",
    "        ex = generate_synthetic_example()\n",
    "        inp = example_to_input_json(ex)\n",
    "        out = ex.plan\n",
    "        data.append({\"input\": inp, \"label\": out})\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train / Validation Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating synthetic examples: 100%|██████████| 100/100 [00:00<00:00, 38657.18it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(80, 20)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_TRAIN = 80   # you can increase if you have GPU capacity\n",
    "NUM_VAL = 20\n",
    "\n",
    "full_data = generate_dataset(NUM_TRAIN + NUM_VAL)\n",
    "train_data = full_data[:NUM_TRAIN]\n",
    "val_data = full_data[NUM_TRAIN:NUM_TRAIN + NUM_VAL]\n",
    "\n",
    "len(train_data), len(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Prepare Tokenizer and LLM with LoRA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 3,686,400 || all params: 3,089,625,088 || trainable%: 0.1193\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(LLM_BASE_NAME, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    LLM_BASE_NAME,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    device_map=\"auto\" if device == \"cuda\" else None,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# LoRA config\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = get_peft_model(base_model, lora_config)\n",
    "model.print_trainable_parameters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Build Hugging Face Datasets with Chat Templates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 80/80 [00:00<00:00, 524.92 examples/s]\n",
      "Map: 100%|██████████| 20/20 [00:00<00:00, 557.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def build_hf_dataset(data: List[Dict[str, Any]]) -> HFDataset:\n",
    "    return HFDataset.from_list(data)\n",
    "\n",
    "\n",
    "hf_train = build_hf_dataset(train_data)\n",
    "hf_val = build_hf_dataset(val_data)\n",
    "\n",
    "def format_example(example: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(example[\"input\"], indent=2)},\n",
    "        {\"role\": \"assistant\", \"content\": json.dumps(example[\"label\"], indent=2)},\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=False,\n",
    "    )\n",
    "    tokenized = tokenizer(text, truncation=True, max_length=1024)\n",
    "    input_ids = tokenized[\"input_ids\"]\n",
    "    labels = input_ids.copy()\n",
    "    return {\n",
    "        \"input_ids\": input_ids,\n",
    "        \"attention_mask\": tokenized[\"attention_mask\"],\n",
    "        \"labels\": labels,\n",
    "    }\n",
    "\n",
    "hf_train_tok = hf_train.map(\n",
    "    format_example,\n",
    "    batched=False,\n",
    "    remove_columns=hf_train.column_names,\n",
    ")\n",
    "hf_val_tok = hf_val.map(\n",
    "    format_example,\n",
    "    batched=False,\n",
    "    remove_columns=hf_val.column_names,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Train the LoRA-Adapted LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "972ca4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:19, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.654800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20' max='20' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20/20 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3990508317947388, 'eval_runtime': 1.9971, 'eval_samples_per_second': 10.015, 'eval_steps_per_second': 10.015, 'epoch': 1.0}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# Hard-disable Weights & Biases so it never prompts for an API key\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "os.environ[\"WANDB_MODE\"] = \"offline\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "\n",
    "# Optional: also silence some HF telemetry/warnings\n",
    "os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "os.environ[\"TRANSFORMERS_NO_ADVISORY_WARNINGS\"] = \"1\"\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=2e-4,\n",
    "    logging_steps=20,\n",
    "    # NOTE:\n",
    "    # - We intentionally omit evaluation_strategy / eval_steps / save_steps / save_total_limit\n",
    "    #   for compatibility with older transformers versions.\n",
    "    # - If your version supports fp16/bf16 and report_to/remove_unused_columns,\n",
    "    #   you can re-add them here.\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=hf_train_tok,\n",
    "    eval_dataset=hf_val_tok,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "\n",
    "# Manual evaluation after training\n",
    "metrics = trainer.evaluate()\n",
    "print(metrics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation Utilities (JSON Validity, Schema Compliance, Task Accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Eval: 100%|██████████| 5/5 [01:21<00:00, 16.33s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'json_valid_rate': 0.8, 'schema_ok_rate': 0.8, 'exact_match_rate': 0.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def safe_json_loads(s: str) -> Any:\n",
    "    try:\n",
    "        return json.loads(s)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "\n",
    "def evaluate_on_dataset(\n",
    "    dataset: List[Dict[str, Any]],\n",
    "    max_samples: int = 50,\n",
    "    temperature: float = 0.1,\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Quick evaluation on a subset of (input, label) pairs.\"\"\"\n",
    "    model.eval()\n",
    "    correct_exact = 0\n",
    "    json_valid = 0\n",
    "    schema_ok = 0\n",
    "    n = min(max_samples, len(dataset))\n",
    "\n",
    "    for i in tqdm(range(n), desc=\"Eval\"):\n",
    "        sample = dataset[i]\n",
    "        input_obj = sample[\"input\"]\n",
    "        true_plan = sample[\"label\"]\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "            {\"role\": \"user\", \"content\": json.dumps(input_obj, indent=2)},\n",
    "        ]\n",
    "        prompt = tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True,\n",
    "        )\n",
    "\n",
    "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            gen_ids = model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=512,\n",
    "                do_sample=True,\n",
    "                temperature=temperature,\n",
    "            )\n",
    "\n",
    "        gen_text = tokenizer.decode(\n",
    "            gen_ids[0][inputs[\"input_ids\"].shape[1]:],\n",
    "            skip_special_tokens=True,\n",
    "        ).strip()\n",
    "\n",
    "        if \"{\" in gen_text and \"}\" in gen_text:\n",
    "            first = gen_text.find(\"{\")\n",
    "            last = gen_text.rfind(\"}\")\n",
    "            gen_text = gen_text[first:last+1]\n",
    "\n",
    "        obj = safe_json_loads(gen_text)\n",
    "        if obj is not None:\n",
    "            json_valid += 1\n",
    "            expected_keys = {\n",
    "                \"available_modes\",\n",
    "                \"disallowed_modes\",\n",
    "                \"distance_km\",\n",
    "                \"estimated_travel_time_hours\",\n",
    "                \"reasoning\",\n",
    "            }\n",
    "            if set(obj.keys()) == expected_keys:\n",
    "                schema_ok += 1\n",
    "\n",
    "            try:\n",
    "                if (\n",
    "                    set(obj[\"available_modes\"]) == set(true_plan[\"available_modes\"])\n",
    "                    and set(obj[\"disallowed_modes\"]) == set(true_plan[\"disallowed_modes\"])\n",
    "                ):\n",
    "                    correct_exact += 1\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    return {\n",
    "        \"json_valid_rate\": json_valid / n,\n",
    "        \"schema_ok_rate\": schema_ok / n,\n",
    "        \"exact_match_rate\": correct_exact / n,\n",
    "    }\n",
    "\n",
    "\n",
    "eval_metrics = evaluate_on_dataset(val_data, max_samples=5)\n",
    "eval_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Vision-Language Front-End (Qwen-VL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "607f3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2256840d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, AutoModelForVision2Seq\n",
    "\n",
    "# vlm_processor = AutoProcessor.from_pretrained(VLM_MODEL_NAME, trust_remote_code=True)\n",
    "# vlm_model = AutoModelForVision2Seq.from_pretrained(\n",
    "#     VLM_MODEL_NAME,\n",
    "#     # torch_dtype=torch.float16,\n",
    "#     load_in_4bit=True,\n",
    "#     device_map=\"cuda\",\n",
    "#     trust_remote_code=True,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1286691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "def extract_json_block(text: str):\n",
    "    \"\"\"\n",
    "    Extract the FIRST valid top-level JSON object from a string.\n",
    "    No regex with recursion. Works with any VLM output.\n",
    "    \"\"\"\n",
    "    start = text.find(\"{\")\n",
    "    if start == -1:\n",
    "        return None\n",
    "\n",
    "    depth = 0\n",
    "    for i in range(start, len(text)):\n",
    "        if text[i] == \"{\":\n",
    "            depth += 1\n",
    "        elif text[i] == \"}\":\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                block = text[start : i + 1]\n",
    "                return block\n",
    "\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_animal_attributes_from_image(image_path: str) -> Dict[str, Any]:\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    img = img.resize((256, 256), Image.LANCZOS)\n",
    "\n",
    "    prompt = (\n",
    "        \"Analyze the provided animal image.\\n\"\n",
    "        \"Return ONLY valid JSON with EXACT keys:\\n\"\n",
    "        \"animal_name, animal_category, size_class, is_domesticated, dangerous_to_humans.\"\n",
    "    )\n",
    "\n",
    "    # → Multimodal chat (correct for Vision2Seq)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"image\", \"image\": img},\n",
    "                {\"type\": \"text\",  \"text\": prompt},\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    text = vlm_processor.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    # Encode multimodal input\n",
    "    inputs = vlm_processor(\n",
    "        text=[text],\n",
    "        images=[img],\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # Move to GPU\n",
    "    for k, v in inputs.items():\n",
    "        if torch.is_tensor(v):\n",
    "            inputs[k] = v.to(\"cuda\")\n",
    "\n",
    "    # Generate\n",
    "    with torch.no_grad():\n",
    "        output = vlm_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            temperature=0.0,\n",
    "            do_sample=False\n",
    "        )\n",
    "\n",
    "    decoded = vlm_processor.batch_decode(output, skip_special_tokens=True)[0]\n",
    "\n",
    "    # Extract JSON cleanly\n",
    "    json_block = extract_json_block(decoded)\n",
    "    if json_block is None:\n",
    "        print(\"[VLM RAW OUTPUT]:\\n\", decoded)\n",
    "        raise ValueError(\"Failed to extract JSON from VLM output.\")\n",
    "\n",
    "    attrs = json.loads(json_block)\n",
    "\n",
    "    # Defaults\n",
    "    attrs.setdefault(\"animal_name\", \"unknown\")\n",
    "    attrs.setdefault(\"animal_category\", \"wild_dangerous\")\n",
    "    attrs.setdefault(\"size_class\", \"large\")\n",
    "    attrs[\"is_domesticated\"] = bool(attrs.get(\"is_domesticated\", False))\n",
    "    attrs[\"dangerous_to_humans\"] = bool(attrs.get(\"dangerous_to_humans\", True))\n",
    "\n",
    "    return attrs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a5d52",
   "metadata": {},
   "source": [
    "## 9. Full Pipeline: Image → Attributes → Distance → JSON Transport Plan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a245729",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcadbb32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov 23 23:05:51 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  Tesla V100-SXM2-16GB            Off| 00000000:00:05.0 Off |                    0 |\n",
      "| N/A   35C    P0               50W / 300W|   7051MiB / 16384MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A       832      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      6180      C   ...r/miniconda3/envs/animal/bin/python     7044MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32423d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VLM] Using device: cuda\n",
      "[VLM] Loading processor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[VLM] Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:15<00:00,  7.53s/it]\n"
     ]
    }
   ],
   "source": [
    "## 9.VLM-1 — Import and initialize VLM\n",
    "\n",
    "import base64\n",
    "import sys\n",
    "\n",
    "# Make sure project module can be imported\n",
    "sys.path.insert(0, \"src\")\n",
    "\n",
    "from animal_transport.api.inference_vlm import get_vlm_wrapper\n",
    "\n",
    "# Initialize VLM instance\n",
    "vlm = get_vlm_wrapper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e359f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 9.VLM-2 — Analyze a single image with the VLM\n",
    "\n",
    "def run_vlm_on_image(image_path: str):\n",
    "    # Load image → base64 string\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        img_base64 = base64.b64encode(f.read()).decode()\n",
    "\n",
    "    # Call your VLM wrapper\n",
    "    result = vlm.analyze_animal(img_base64)\n",
    "\n",
    "    print(\"\\n[VLM Output JSON]:\")\n",
    "    print(result)\n",
    "    return result\n",
    "## 10.2 — LLM Transport Planner (JSON-in → JSON-out)\n",
    "\n",
    "import json\n",
    "import torch\n",
    "\n",
    "def run_llm_planner(vlm_json: dict, temperature: float = 0.1):\n",
    "    \"\"\"\n",
    "    Given the VLM JSON attributes, ask the fine-tuned LLM to produce a transport plan.\n",
    "    Assumes SYSTEM_PROMPT, tokenizer, model, safe_json_loads exist globally.\n",
    "    \"\"\"\n",
    "\n",
    "    # The LLM expects exactly this input format:\n",
    "    user_input = {\n",
    "        \"animal_category\": vlm_json[\"animal_category\"],\n",
    "        \"size_class\": vlm_json[\"size_class\"],\n",
    "        \"is_domesticated\": vlm_json[\"is_domesticated\"],\n",
    "        \"dangerous_to_humans\": vlm_json[\"dangerous_to_humans\"],\n",
    "        # Put dummy coords + distance (the planner needs them)\n",
    "        \"origin\": {\"lat\": 10.0, \"lon\": 10.0},\n",
    "        \"destination\": {\"lat\": 20.0, \"lon\": 20.0},\n",
    "        \"distance_km\": 150.0\n",
    "    }\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": json.dumps(user_input, indent=2)},\n",
    "    ]\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        messages,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=512,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "        )\n",
    "\n",
    "    gen_text = tokenizer.decode(\n",
    "        out[0][inputs[\"input_ids\"].shape[1]:],\n",
    "        skip_special_tokens=True\n",
    "    ).strip()\n",
    "\n",
    "    # Extract JSON\n",
    "    if \"{\" in gen_text and \"}\" in gen_text:\n",
    "        js = gen_text[gen_text.find(\"{\") : gen_text.rfind(\"}\")+1]\n",
    "    else:\n",
    "        js = gen_text\n",
    "\n",
    "    parsed = safe_json_loads(js)\n",
    "\n",
    "    print(\"\\n[LLM → Transport Plan]:\")\n",
    "    if parsed:\n",
    "        print(json.dumps(parsed, indent=2))\n",
    "    else:\n",
    "        print(\"⚠️ Not valid JSON\\nRaw output:\")\n",
    "        print(gen_text)\n",
    "\n",
    "    return parsed, gen_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2dd00a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[VLM Output JSON]:\n",
      "{'animal_name': 'parrot', 'animal_category': 'bird', 'size_class': 'medium', 'is_domesticated': False, 'dangerous_to_humans': True}\n",
      "\n",
      "[LLM → Transport Plan]:\n",
      "{\n",
      "  \"available_modes\": [\n",
      "    \"aircraft\",\n",
      "    \"ship\"\n",
      "  ],\n",
      "  \"disallowed_modes\": [\n",
      "    \"road\",\n",
      "    \"railway\",\n",
      "    \"water\"\n",
      "  ],\n",
      "  \"distance_km\": 150.0,\n",
      "  \"estimated_travel_time_hours\": {\n",
      "    \"aircraft\": 2.0,\n",
      "    \"ship\": 3.0\n",
      "  },\n",
      "  \"reasoning\": \"Birds of medium size that are not domesticated and are dangerous to humans can be transported by aircraft or ship. Road, railway, and water transport are not suitable due to potential risks.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## 10.3 — Full Pipeline on One Image\n",
    "\n",
    "image_path = \"tests/bird.avif\"   # change as needed\n",
    "\n",
    "# Step 1 — VLM\n",
    "vlm_json = run_vlm_on_image(image_path)\n",
    "\n",
    "# Step 2 — LLM\n",
    "plan_json, raw = run_llm_planner(vlm_json)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abb5c1f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[VLM Output JSON]:\n",
      "{'animal_name': 'tiger', 'animal_category': 'wild', 'size_class': 'large', 'is_domesticated': False, 'dangerous_to_humans': True}\n",
      "\n",
      "[LLM → Transport Plan]:\n",
      "{\n",
      "  \"available_modes\": [\n",
      "    \"truck\"\n",
      "  ],\n",
      "  \"disallowed_modes\": [\n",
      "    \"car\",\n",
      "    \"bus\",\n",
      "    \"train\",\n",
      "    \"plane\"\n",
      "  ],\n",
      "  \"distance_km\": 150.0,\n",
      "  \"estimated_travel_time_hours\": {\n",
      "    \"truck\": 18.0\n",
      "  },\n",
      "  \"reasoning\": \"Large wild animals that are dangerous to humans should be transported by truck due to their size and potential threat to passengers. Other modes of transport are not suitable due to safety concerns.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "## 10.3 — Full Pipeline on One Image\n",
    "\n",
    "image_path = \"tests/tiger.jpg\"   # change as needed\n",
    "\n",
    "# Step 1 — VLM\n",
    "vlm_json = run_vlm_on_image(image_path)\n",
    "\n",
    "# Step 2 — LLM\n",
    "plan_json, raw = run_llm_planner(vlm_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb2ab6",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "This notebook implements:\n",
    "\n",
    "- A deterministic rule system for animal transport modes.  \n",
    "- Synthetic instruction-tuning data generation using that rule system.  \n",
    "- LoRA fine-tuning of a Qwen-style 3B LLM for JSON-structured outputs.  \n",
    "- A Qwen-VL-based front-end that infers animal attributes from images.  \n",
    "- A full pipeline from image to finalized JSON transport plan.\n",
    "\n",
    "You can now:\n",
    "- Adjust the rules in the rule engine for your domain.\n",
    "- Increase dataset size and training epochs for better performance.\n",
    "- Replace model names with local / smaller variants if your hardware is limited.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
